{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to add instructions on \n",
    "* install bleeding edge lasagne & theano\n",
    "* are we to assume that if they can open the notebook they are good?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A pure python neural network model of reflex conditioning in animal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses the following packages:\n",
    "* [Lasagne](http://lasagne.readthedocs.io/en/stable/index.html) :: A neural network framework built on Theano\n",
    "* [Numpy](http://www.numpy.org/) :: Scientific computing packaging\n",
    "* [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) :: Data manipulation, munging, formatting library\n",
    "* [Theano](http://www.deeplearning.net/software/theano/) :: Deep learning framework\n",
    "* [Matplotlib.pyplot](https://matplotlib.org/api/pyplot_api.html) :: Visualization\n",
    "\n",
    "Begin by importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: If a warning DEPRACATED populates, set a USER variable defined as THEANO_FLAGS to an empty string.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constansts for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## Define Constants #################################\n",
    "N_CS = 5\n",
    "N_CONTEXT = 10\n",
    "N_SAMPLES = 25\n",
    "N_BATCHES = 250\n",
    "N_SIMS = 20\n",
    "output_file = 'output.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function builds the dataset or input vector.  The dataset is a 2-dimensional binary array consisting of an initial 5 element CS, or *conditioned stimulus* portion and a 10 element context portion.  The length of each piece, and thus the dataset, is controlled using constants defined above. The `cs[rand_num][0] = 1.0` portion sets the value of the 1st element of a random vector within the array to 1, this correlates to *stimulus present*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(n_cs=N_CS, n_context=N_CONTEXT, n_samples=N_SAMPLES):\n",
    "    # build out cs portion of input var\n",
    "    cs = [[0 for i in range(n_cs)] for j in range(n_samples)]\n",
    "    rand_num = np.random.randint(0, high=len(cs))\n",
    "    cs[rand_num][0] = 1.0\n",
    "\n",
    "    # build out context portion of input var\n",
    "    context = [float(np.random.randint(0, high=2)) for i in range(n_context)]\n",
    "\n",
    "    # build input var\n",
    "    input_var = []\n",
    "    for array_item in cs:\n",
    "        input_var.append(array_item + context)\n",
    "    return np.asarray(input_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, defining a function to build targets for a loss function within the model.  The previously built dataset is used a reference point when building the targets to mitigate any errors while running the loss function.  The `cs_index = targets.index(1.)` saves the index of the *stimulus present* vector within the larger dataset array for use in later parts of the application. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_targets(input_var):\n",
    "    targets = []\n",
    "    for item in input_var:\n",
    "        if np.any(item[0] == 1.0):\n",
    "            targets.append(1.0)\n",
    "        else:\n",
    "            targets.append(0.0)\n",
    "    cs_index = targets.index( 1.)\n",
    "    return np.asarray(targets), cs_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to building the network..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose to use lasagne library because of its restraint in abstracting away all of the lower level theano functionality.  Within the context of the experiment, it was not only important to see the activations and weights at the layer level, but also to be able to grab and manipulate them.  Other popular neural net libraries do not provide this acccess out of the box.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the cortical network has 2 different training points, i.e. the *lower layer* weights with the hippocampal hidden layer activations, and the *upper layer* weights with the targets data outlined above; each piece of the cortical network had to built separately. This initial function defines the architecture of the lower cortical network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################## Build Lower Cortical Network #############################\n",
    "def build_cort_low_net(input_var=None):\n",
    "    l_input = lasagne.layers.InputLayer(shape=(None, 15),\n",
    "                                        input_var=input_var)\n",
    "    l_output = lasagne.layers.DenseLayer(\n",
    "                l_input,\n",
    "                num_units=40,\n",
    "                W=lasagne.init.Uniform(range=3.0),\n",
    "                nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    return l_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network consists of an **Input Layer** accepting a dataset of shape `(None, 15)` where the *None* parameter indicates the size of that dimension is not fixed.  This is followed by a fully connected **Dense Layer** with 40 nodes and a *rectify* activation function.  The weights matrix values are initialized as a random number between *-3 and 3* using [init.Uniform](https://lasagne.readthedocs.io/en/latest/modules/init.html#lasagne.init.Uniform) method.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper cortical network is defined with similar layers to the lower cortical network with the following differences.\n",
    "1. The **Input Layer** accepts input with shape `(None, 40`) matching the output of the lower cortical network\n",
    "2. The **Dense Layer** consists of a single node, matching the desired network output\n",
    "3. A *sigmoid* activation function is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################## Build Upper Cortical Network #############################\n",
    "def build_cort_up_net(input_var=None):\n",
    "    l_input = lasagne.layers.InputLayer(shape=(None, 40),\n",
    "                                        input_var=input_var)\n",
    "    l_output = lasagne.layers.DenseLayer(\n",
    "                l_input,\n",
    "                num_units=1,\n",
    "                W=lasagne.init.Uniform(range=3.0),\n",
    "                nonlinearity=lasagne.nonlinearities.sigmoid)\n",
    "    return l_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
